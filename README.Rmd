---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
devtools::load_all()
```

[![Travis-CI Build Status](https://travis-ci.org/TysonStanley/autoscore.svg?branch=master)](https://travis-ci.org/TysonStanley/autoscore)
![](https://img.shields.io/badge/lifecycle-maturing-blue.svg)

# `autoscore` <img src="man/figures/autoscore_logo.png" align="right" width="30%" height="30%" />

> R Package: `r packageVersion("autoscore")`

> Shiny App: temporary location at [https://tysonstanley.shinyapps.io/autoscore/](https://tysonstanley.shinyapps.io/autoscore/)

*Authors:*

- *Tyson S. Barrett*
- *Stephanie A. Borrie*
- *Sarah E. Yoho*

The purpose of `autoscore` is to automatically score word identification in speech perception research, such as studies involving listener understanding of speech in background noise or disordered speech. The program uses a flexible number of rules that determine whether a response set of words (i.e., listener transcriptions) match a target set of words (i.e., speech corpus). At the most basic level, Autoscore counts words in the listener transcript as correct if they match the words in the target phrase exactly (regardless of word order), or match a homophone or common misspelling of the target word. Individual rules can be applied or removed, depending on the needs of researcher and the scoring rules of the research lab. Examples of rules available in Autoscore include the ability to count as correct substitutions of articles (A for The) or differences in plural or tense (adding -s or -ed to a word). Additional rules can be added by the researcher as needed.

The rule options are categorized into either spelling rules or grammar rules.

#### Spelling Rules


1. `homophone_rule` = response word counted correct if it is a homophone of the target word; default is to use this rule (`default = TRUE`)
2. `common_misspell_rule` = use a default list of [common misspellings](https://en.wikipedia.org/wiki/Wikipedia:Lists_of_common_misspellings/For_machines) to be scored as correct; `default = TRUE`
3. `acceptable_spell_rule` = use a researcher uploaded acceptable spelling list to be scored as correct; this rule is triggered when the researcher provides a data file
4. `suffix_rule` = stem all words (i.e., remove all suffixes); `default is TRUE`
5. `rootword_rule` = response word counted correct if the target word (e.g., bat, day) is embedded at either the beginning (e.g., batman) or end (e.g., monday) of the word; uses a partial matching heuristic; `default is FALSE`
6. `double_letter_rule` = should double letters within words be considered the same as if there was only one? E.g., "attack" is a match with "atack"; `default = FALSE`


#### Grammar Rules

7. `pasttense_rule` = response word counted correct if it differs from the target word only by tense; `default is TRUE`
8. `a_the_rule` = substitutions between “a” and “the” to be scored as correct; `default is TRUE`
9. `plural_rule` = response word counted correct if it differs from the target word only by plurality; `default is TRUE`


## Design

The API of the `R` package is simple. A single call to `autoscore()` with the formatted data will run everything for you. This function is a composite of several sub-functions that do various jobs:

- `select_cols()` -- The first function which takes the data and gets it in the right format for analysis.
- `split_clean()` -- Using the cleaned data from `select_cols()`, this uses `stringr` to turn the phrases into individual words.
- `alternate_fun()` -- If a data.frame of alternate spellings is provided, this function will find and normalize all alternate spellings to match the original spelling as defined by the researcher.
- `homophones_fun()` -- If homophones are used (according to the `homophone_rule`), this function finds and normalizes all homophones as found in the `data(homophones)` found in this package.
- `match_position_basic()` -- This function is the workhorse of the package. It takes the cleaned (and possibly homophone normalized) data and does three main things: 1) applies all the rules except for the `position_rule`, 2) finds the matches between the responses and the targets, and 3) reports how far away the matches are from each other.
- `count_matches()` -- Finally, this function takes the information from `match_position_basic()` and counts the number of matches based on the `position_rule`.

Beyond the main analysis when using `autoscore()`, we can also call `pwc()` to get the percent words correct (based on the number of target words) for each observation.


## Use of the Online Tool

Visit [https://tysonstanley.shinyapps.io/autoscore/](https://tysonstanley.shinyapps.io/autoscore/) to use the online tool. Instructions for its use are found there.

<img src="man/figures/online_autoscore_snapshot.png" align="center" width="70%" height="70%" />


## Use of the R Package

To install the package use the developmental version as it is not yet on CRAN.
```{r, eval = FALSE}
devtools::install_github("tysonstanley/autoscore_package")
```

An example of the use of `autoscore` is below. We will use the example data set provided in the package.

```{r}
library(tidyverse)
library(autoscore)

data("example_data")
example_data
```

First, let's use all the defaults and look at the first 10 rows of the output.
```{r}
example_data %>%
  autoscore() %>%   ## using all the defaults
  as.tibble()       ## to shorted output
```

Next, let's change some of the rules.
```{r}
example_data %>%
  autoscore(position_rule = 2, suffix_rule = FALSE, plurals_rule = FALSE) %>%
  as.tibble()
```

We can also change the output type to "none" to get all the data from the computation.
```{r}
example_data %>%
  autoscore(output = "none")
```

To use the acceptable spelling rule, let's create a small `data.frame` that we can provide `autoscore()`. In the data frame below, the target spellings are the generally accepted spellings that are in the target list of words while the acceptable_response spellings are those that should also be counted as correct.

```{r}
acceptable_df <- data_frame(
  target = c("model",
             "treason",
             "duck"),
  acceptable_response = c("modal, moddel",
                          "treeson",
                          "dock")
)
acceptable_df
```

Using this, we can provide it to the `autoscore()` function with the `acceptable_df` argument.

```{r}
example_data %>%
  autoscore::autoscore(acceptable_df = acceptable_df) %>%
  as.tibble()
```

We can also say `common_misspell_rule = TRUE` in conjunction with `acceptable_df = acceptable_df` if we want to use the list of 4,268 common misspellings in addition to the user provided list.

```{r}
example_data %>%
  autoscore::autoscore(acceptable_df = acceptable_df,
                       common_misspell_rule = TRUE) %>%
  as.tibble()
```

If the researcher doesn't have a list of words, we can just use the common misspell rule.

```{r}
example_data %>%
  autoscore::autoscore(common_misspell_rule = TRUE) %>%
  as.tibble()
```

In each of these examples, it is clear that the human and "autoscore" agree the majority of the time. The times that they disagree, it is usually predictably a human error or a subjective judgement that the researcher will have to consider (for example by including alternate spellings of words as we just demonstrated).

### Learn More

Publications are forthcoming. For more information, contact Tyson S. Barrett (t.barrett@aggiemail.usu.edu).


